// Decompiled with JetBrains decompiler
// Type: Windows.Media.Audio.AudioGraph
// Assembly: Windows.Foundation.UniversalApiContract, Version=14.0.0.0, Culture=neutral, PublicKeyToken=null, ContentType=WindowsRuntime
// MVID: F62EFE2D-E4C7-4EB8-B17A-E7D33D1BB49F
// Assembly location: C:\Users\codyc\.nuget\packages\microsoft.windows.sdk.contracts\10.0.22000.196\ref\netstandard2.0\Windows.Foundation.UniversalApiContract.winmd

using System.Runtime.CompilerServices;
using Windows.Devices.Enumeration;
using Windows.Foundation;
using Windows.Foundation.Metadata;
using Windows.Media.Capture;
using Windows.Media.Core;
using Windows.Media.MediaProperties;
using Windows.Storage;

namespace Windows.Media.Audio
{
  /// <summary>Represents an audio graph of connected input, output, and submix nodes that manipulate and route audio.</summary>
  [ContractVersion(typeof (UniversalApiContract), 65536)]
  [MarshalingBehavior(MarshalingType.Agile)]
  [Threading(ThreadingModel.Both)]
  [DualApiPartition(version = 167772160)]
  [Static(typeof (IAudioGraphStatics), 65536, "Windows.Foundation.UniversalApiContract")]
  public sealed class AudioGraph : IAudioGraph, IClosable, IAudioGraph2, IAudioGraph3
  {
    /// <summary>Creates an AudioFrameInputNode that inputs audio data generated by app-implemented code into the audio graph.</summary>
    /// <returns>An audio frame input node.</returns>
    [Overload("CreateFrameInputNode")]
    [MethodImpl]
    public extern AudioFrameInputNode CreateFrameInputNode();

    /// <summary>Creates an AudioFrameInputNode, with the specified encoding properties, that inputs audio data generated by app-implemented code into the audio graph.</summary>
    /// <param name="encodingProperties">An object representing the audio encoding properties for the frame input node which specifies the sample rate at which the created node will operate. Only uncompressed PCM and float formats are allowed.</param>
    /// <returns>An audio frame input node.</returns>
    [Overload("CreateFrameInputNodeWithFormat")]
    [MethodImpl]
    public extern AudioFrameInputNode CreateFrameInputNode(
      AudioEncodingProperties encodingProperties);

    /// <summary>Creates an AudioDeviceInputNode that inputs audio data into the audio graph from the default audio input device, such as a microphone or audio card.</summary>
    /// <param name="category">A value from the MediaCategory enumeration value indicating the category of the media processed by this node, allowing the system to perform content-appropriate processing and prioritization of the media.</param>
    /// <returns>An asynchronous operation that returns a CreateAudioDeviceInputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The DeviceInputNode property provides a reference to the created input node on success.</returns>
    [RemoteAsync]
    [Overload("CreateDeviceInputNodeAsync")]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioDeviceInputNodeResult> CreateDeviceInputNodeAsync(
      MediaCategory category);

    /// <summary>Creates an AudioDeviceInputNode that inputs audio data into the audio graph from the default audio input device such as a microphone or audio card.</summary>
    /// <param name="category">A value from the MediaCategory enumeration value indicating the category of the media processed by this node, allowing the system to perform content-appropriate processing and prioritization of the media.</param>
    /// <param name="encodingProperties">An object representing the audio encoding properties for the device input node which specifies the sample rate at which the created node will operate. Only uncompressed PCM and float formats are allowed.</param>
    /// <returns>An asynchronous operation that returns a CreateAudioDeviceInputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The DeviceInputNode property provides a reference to the created input node on success.</returns>
    [RemoteAsync]
    [Overload("CreateDeviceInputNodeWithFormatAsync")]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioDeviceInputNodeResult> CreateDeviceInputNodeAsync(
      MediaCategory category,
      AudioEncodingProperties encodingProperties);

    /// <summary>Creates an AudioDeviceInputNode that inputs audio data into the audio graph from the specified audio input device such as a microphone or audio card.</summary>
    /// <param name="category">A value from the MediaCategory enumeration value indicating the category of the media processed by this node, allowing the system to perform content-appropriate processing and prioritization of the media.</param>
    /// <param name="encodingProperties">An object representing the audio encoding properties for the device input node which specifies the sample rate at which the created node will operate. Only uncompressed PCM and float formats are allowed.</param>
    /// <param name="device">A DeviceInformation object representing the device from which the device input node will get audio data.</param>
    /// <returns>An asynchronous operation that returns a CreateAudioDeviceInputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The DeviceInputNode property provides a reference to the created input node on success.</returns>
    [RemoteAsync]
    [Overload("CreateDeviceInputNodeWithFormatOnDeviceAsync")]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioDeviceInputNodeResult> CreateDeviceInputNodeAsync(
      MediaCategory category,
      AudioEncodingProperties encodingProperties,
      DeviceInformation device);

    /// <summary>Creates a new AudioFrameOutputNode that outputs audio data from the audio graph to app-implemented code.</summary>
    /// <returns>An audio frame output node.</returns>
    [Overload("CreateFrameOutputNode")]
    [MethodImpl]
    public extern AudioFrameOutputNode CreateFrameOutputNode();

    /// <summary>Creates a new AudioFrameOutputNode, with the specified encoding properties, that outputs audio data from the audio graph to app-implemented code.</summary>
    /// <param name="encodingProperties">An object representing the audio encoding properties for the frame output node which specifies the sample rate at which the created node will operate. Only uncompressed PCM and float formats are allowed.</param>
    /// <returns>An audio frame output node.</returns>
    [Overload("CreateFrameOutputNodeWithFormat")]
    [MethodImpl]
    public extern AudioFrameOutputNode CreateFrameOutputNode(
      AudioEncodingProperties encodingProperties);

    /// <summary>Creates a new AudioDeviceOutputNode that outputs audio data from the audio graph to the system's default output device, such as speakers or headphones.</summary>
    /// <returns>An asynchronous operation that returns a CreateAudioDeviceOutputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The DeviceOutputNode property provides a reference to the created output node on success.</returns>
    [RemoteAsync]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioDeviceOutputNodeResult> CreateDeviceOutputNodeAsync();

    /// <summary>Creates an AudioFileInputNode that inputs audio data into the audio graph from a storage file.</summary>
    /// <param name="file">A StorageFile object representing the audio file associated with the input node.</param>
    /// <returns>An asynchronous operation that returns a CreateAudioFileInputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The FileInputNode property provides a reference to the created output node on success.</returns>
    [RemoteAsync]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioFileInputNodeResult> CreateFileInputNodeAsync(
      IStorageFile file);

    /// <summary>Creates a new AudioFileOutuputNode that outputs audio data from the audio graph to the specified storage file.</summary>
    /// <param name="file">A StorageFile to which audio data is written.</param>
    /// <returns>An asynchronous operation that returns a CreateAudioFileOutputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The FileOutputNode property provides a reference to the created output node on success.</returns>
    [RemoteAsync]
    [Overload("CreateFileOutputNodeAsync")]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioFileOutputNodeResult> CreateFileOutputNodeAsync(
      IStorageFile file);

    /// <summary>Creates a new AudioFileOutuputNode that outputs audio data from the audio graph to the specified storage file.</summary>
    /// <param name="file">A StorageFile to which audio data is written.</param>
    /// <param name="fileEncodingProfile">A MediaEncodingProfile that determines the format of the output file.</param>
    /// <returns>An asynchronous operation that returns a CreateAudioFileOutputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The FileOutputNode property provides a reference to the created output node on success.</returns>
    [Overload("CreateFileOutputNodeWithFileProfileAsync")]
    [RemoteAsync]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioFileOutputNodeResult> CreateFileOutputNodeAsync(
      IStorageFile file,
      MediaEncodingProfile fileEncodingProfile);

    /// <summary>Creates an AudioSubmixNode that mixes the output of one or more audio graph nodes into a single output that can be connected to output nodes or other submix nodes.</summary>
    /// <returns>An audio submix node.</returns>
    [Overload("CreateSubmixNode")]
    [MethodImpl]
    public extern AudioSubmixNode CreateSubmixNode();

    /// <summary>Creates an AudioSubmixNode that mixes the output of one or more audio graph nodes into a single output that can be connected to output nodes or other submix nodes.</summary>
    /// <param name="encodingProperties">An object representing the audio encoding properties for the submix node which specifies the sample rate at which the created node will operate. Only uncompressed PCM and float formats are allowed.</param>
    /// <returns>An audio submix node.</returns>
    [Overload("CreateSubmixNodeWithFormat")]
    [MethodImpl]
    public extern AudioSubmixNode CreateSubmixNode(
      AudioEncodingProperties encodingProperties);

    /// <summary>Starts the audio graph.</summary>
    [MethodImpl]
    public extern void Start();

    /// <summary>Stops the audio graph.</summary>
    [MethodImpl]
    public extern void Stop();

    /// <summary>Resets all nodes in the audio graph.</summary>
    [MethodImpl]
    public extern void ResetAllNodes();

    /// <summary>Notifies that the audio graph has started processing a new quantum.</summary>
    public extern event TypedEventHandler<AudioGraph, object> QuantumStarted;

    /// <summary>Notifies that the audio graph has processed the specified quantum.</summary>
    public extern event TypedEventHandler<AudioGraph, object> QuantumProcessed;

    /// <summary>Notifies of an unrecoverable audio error in audio graph operation.</summary>
    public extern event TypedEventHandler<AudioGraph, AudioGraphUnrecoverableErrorOccurredEventArgs> UnrecoverableErrorOccurred;

    /// <summary>Gets the completed quantum count for the audio graph.</summary>
    /// <returns>A value indicating the completed quantum count.</returns>
    public extern ulong CompletedQuantumCount { [MethodImpl] get; }

    /// <summary>Gets the encoding properties for the audio graph.</summary>
    /// <returns>The encoding properties for the audio graph.</returns>
    public extern AudioEncodingProperties EncodingProperties { [MethodImpl] get; }

    /// <summary>Gets the latency in samples that the audio graph supports.</summary>
    /// <returns>A value indicating the sample latency.</returns>
    public extern int LatencyInSamples { [MethodImpl] get; }

    /// <summary>Gets the primary render device for the audio graph.</summary>
    /// <returns>The primary render device for the audio graph.</returns>
    public extern DeviceInformation PrimaryRenderDevice { [MethodImpl] get; }

    /// <summary>Gets a value that indicates the audio processing mode for the audio graph.</summary>
    /// <returns>A value that indicates the audio processing mode for the audio graph.</returns>
    public extern AudioProcessing RenderDeviceAudioProcessing { [MethodImpl] get; }

    /// <summary>Gets the number of samples per quantum at which the audio graph is currently operating.</summary>
    /// <returns>A value indicating the number of samples per quantum.</returns>
    public extern int SamplesPerQuantum { [MethodImpl] get; }

    [MethodImpl]
    public extern void Close();

    /// <summary>Creates a spatial audio-enabled AudioFrameInputNode, with the specified encoding properties, that inputs audio data generated by app-implemented code into the audio graph.</summary>
    /// <param name="encodingProperties">An object representing the audio encoding properties for the frame input node which specifies the sample rate at which the created node will operate. Only uncompressed PCM and float formats are allowed.</param>
    /// <param name="emitter">An object that describes the position and other physical characteristics of the emitter from which the node's audio is emitted when spatial audio processing is used.</param>
    /// <returns>An audio frame input node.</returns>
    [Overload("CreateFrameInputNodeWithFormatAndEmitter")]
    [MethodImpl]
    public extern AudioFrameInputNode CreateFrameInputNode(
      AudioEncodingProperties encodingProperties,
      AudioNodeEmitter emitter);

    /// <summary>Creates a spatial audio-enabled AudioDeviceInputNode that inputs audio data into the audio graph from the specified audio input device such as a microphone or audio card.</summary>
    /// <param name="category">A value from the MediaCategory enumeration value indicating the category of the media processed by this node, allowing the system to perform content-appropriate processing and prioritization of the media.</param>
    /// <param name="encodingProperties">An object representing the audio encoding properties for the device input node which specifies the sample rate at which the created node will operate. Only uncompressed PCM and float formats are allowed.</param>
    /// <param name="device">A DeviceInformation object representing the device from which the device input node will get audio data.</param>
    /// <param name="emitter">An object that describes the position and other physical characteristics of the emitter from which the node's audio is emitted when spatial audio processing is used.</param>
    /// <returns>An asynchronous operation that returns a CreateAudioDeviceInputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The DeviceInputNode property provides a reference to the created input node on success.</returns>
    [Overload("CreateDeviceInputNodeWithFormatAndEmitterOnDeviceAsync")]
    [RemoteAsync]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioDeviceInputNodeResult> CreateDeviceInputNodeAsync(
      MediaCategory category,
      AudioEncodingProperties encodingProperties,
      DeviceInformation device,
      AudioNodeEmitter emitter);

    /// <summary>Creates a spatial audio-enabled AudioFileInputNode that inputs audio data into the audio graph from a storage file.</summary>
    /// <param name="file">A IStorageFile object representing the audio file associated with the input node.</param>
    /// <param name="emitter">An object that describes the position and other physical characteristics of the emitter from which the node's audio is emitted when spatial audio processing is used.</param>
    /// <returns>An asynchronous operation that returns a CreateAudioFileInputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The FileInputNode property provides a reference to the created input node on success.</returns>
    [RemoteAsync]
    [Overload("CreateFileInputNodeWithEmitterAsync")]
    [MethodImpl]
    public extern IAsyncOperation<CreateAudioFileInputNodeResult> CreateFileInputNodeAsync(
      IStorageFile file,
      AudioNodeEmitter emitter);

    /// <summary>Creates a spatial audio-enabled AudioSubmixNode that mixes the output of one or more audio graph nodes into a single output that can be connected to output nodes or other submix nodes.</summary>
    /// <param name="encodingProperties">An object representing the audio encoding properties for the submix node which specifies the sample rate at which the created node will operate. Only uncompressed PCM and float formats are allowed.</param>
    /// <param name="emitter">An object that describes the position and other physical characteristics of the emitter from which the node's audio is emitted when spatial audio processing is used.</param>
    /// <returns>An audio submix node.</returns>
    [Overload("CreateSubmixNodeWithFormatAndEmitter")]
    [MethodImpl]
    public extern AudioSubmixNode CreateSubmixNode(
      AudioEncodingProperties encodingProperties,
      AudioNodeEmitter emitter);

    /// <summary>Creates a new AudioGraphBatchUpdater for the AudioGraph which causes all subsequent modifications to all nodes in the audio graph to be accumulated and then committed once your app closes or disposes of the batch updater object.</summary>
    /// <returns>A new batch updater for the audio graph.</returns>
    [MethodImpl]
    public extern AudioGraphBatchUpdater CreateBatchUpdater();

    /// <summary>Creates a MediaSourceAudioInputNode that inputs audio data into the audio graph from the provided MediaSource object.</summary>
    /// <param name="mediaSource">The MediaSource object from which audio data is input into the audio graph.</param>
    /// <returns>An IAsyncOperation object that returns a CreateMediaSourceAudioInputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The  Node property provides a reference to the created input node on success.</returns>
    [Overload("CreateMediaSourceAudioInputNodeAsync")]
    [RemoteAsync]
    [MethodImpl]
    public extern IAsyncOperation<CreateMediaSourceAudioInputNodeResult> CreateMediaSourceAudioInputNodeAsync(
      MediaSource mediaSource);

    /// <summary>Creates a spatial audio-enabled MediaSourceAudioInputNode that inputs audio data into the audio graph from the provided MediaSource object.</summary>
    /// <param name="mediaSource">The MediaSource object from which audio data is input into the audio graph.</param>
    /// <param name="emitter">An AudioNodeEmitter object that describes the position and other physical characteristics of the emitter from which the node's audio is emitted when spatial audio processing is used.</param>
    /// <returns>An IAsyncOperation object that returns a CreateMediaSourceAudioInputNodeResult on completion. This object exposes a Status property, that indicates either that the operation was successful or the reason why the operation failed. The  Node property provides a reference to the created input node on success.</returns>
    [RemoteAsync]
    [Overload("CreateMediaSourceAudioInputNodeWithEmitterAsync")]
    [MethodImpl]
    public extern IAsyncOperation<CreateMediaSourceAudioInputNodeResult> CreateMediaSourceAudioInputNodeAsync(
      MediaSource mediaSource,
      AudioNodeEmitter emitter);

    /// <summary>Creates an audio graph with specific settings.</summary>
    /// <param name="settings">An AudioGraphSettings object representing the source audio file.</param>
    /// <returns>When this operation completes, a CreateAudioGraphResult object is returned.</returns>
    [RemoteAsync]
    [MethodImpl]
    public static extern IAsyncOperation<CreateAudioGraphResult> CreateAsync(
      AudioGraphSettings settings);
  }
}
